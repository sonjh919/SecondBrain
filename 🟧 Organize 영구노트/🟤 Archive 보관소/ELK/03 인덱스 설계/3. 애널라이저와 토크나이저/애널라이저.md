#Elasticsearch 

> [!note]+ 
> text 필드의 데이터는 애널라이저를 통해 분석돼 여러 텀([[term]])으로 쪼개져 색인된다. 여기서는 구체적인 애널라이저 동작 과정과 ES가 자체 제공하는 여러 빌트인 애널라이저를 사용하고, 특정 상황에 맞는 커스텀 애널라이저 적용 방법을 살펴볼 수 있다.

## 애널라이저 구조
애널라이저는 0개 이상의 [[캐릭터 필터]], 1개의 [[토크나이저]], 0개 이상의 [[토큰 필터]]로 구성된다. 동작 역시 3단계로 수행된다. ES에는 내장 캐릭터 필터, 토크나이저, 토큰 필터를 조합하여 미리 만들어 놓은 다양한 [[내장 애널라이저]]가 있다.

> [!summary]+ 
> 1. 입력한 텍스트에 캐릭터 필터를 적용하여 문자열을 변형시킨다.
> 2. 토크나이저를 적용하여 여러 토큰으로 쪼갠다.
> 3. 쪼개진 토큰의 스트림에 토큰 필터를 적용해서 토큰에 특정한 변형을 가한 결과가 최종적으로 분석 완료된 텀([[term]])이다.
![[analyzer.jpg]]

## analyze API
ES는 앞에서 설명한 애널라이저와 각 구성 요소의 동작을 쉽게 테스트해볼 수 있는 analyze API를 제공하고 있다.

```json
GET _analyze
POST _analyze
```

> [!example]+ 
> hello, HELLO, World!의 3가지 토큰으로 쪼개진다.
```json
POST _analyze
{
	"analyzer": "standard",
	"text": "Hello, HELLO, World!"
}

//return 
{
  "tokens": [
    {
      "token": "hello",
      "start_offset": 0,
      "end_offset": 5,
      "type": "<ALPHANUM>",
      "position": 0
    },
    {
      "token": "hello",
      "start_offset": 7,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 1
    },
    {
      "token": "world",
      "start_offset": 14,
      "end_offset": 19,
      "type": "<ALPHANUM>",
      "position": 2
    }
  ]
}
```

## 애널라이저를 매핑에 적용
```json
POST analyzer_test
{
  "settings":{
    "analysis":{
      "analyzer":{
        "default":{
          "type": "keyword"
        }
      }
    }
  },
  "mappings":{
    "properties":{
      "defaultText":{
        "type": "text"
      },
      "standardText":{
        "type": "text",
        "analyzer":"standard"
      }
    }
  }
}
```