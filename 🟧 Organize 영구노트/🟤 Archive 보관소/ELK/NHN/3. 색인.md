
# 데이터 색인 구조
데이터가 검색될 수 있는 구조로 변경하기 위해서는 원본 문서를 검색어 토큰들로 변환하는 과정이 필요하다. (=색인)

![[Pasted image 20240402173145.png]]

부분 데이터 색인 : 실시간으로 수정된 상품에 대한 이미 색인된 데이터를 재색인 -> 데이터 정합성 문제 해결

> [!warning]+ 
> 전체 데이터 색인 시에는 부분 데이터 색인이 진행되면 안되고, 부분 데이터 색인 진행 시에는 전체 데이터 색인이 진행되면 안된다.

![[Pasted image 20240402173457.png]]

## 전체 데이터 색인 아키텍처
+ 배치로 storage에 밀어넣고 진행
![[Pasted image 20240402173653.png]]

![[Pasted image 20240402173702.png]]

부분 색인이 돌고 있지 않으면, key를 점유하고 전체 색인 진행 후 key 삭제
![[Pasted image 20240402173758.png]]

전체 색인 시 항상 새로운 인덱스를 생성하고 기존에 사용 중이던 인덱스는 백업용으로 보관
![[Pasted image 20240402173913.png]]

### bulk
엘라스틱 서치에서는 bulk api 제공
약 3,000,000 이상의 데이터를 5000개 씩 끊어서 벌크 날리게 세팅 -> 전체 세팅 완료 시 50분~1시간
![[Pasted image 20240402174336.png]]

-> 전체 색인 도중 장애 발생, 롤백 필요한 경우..?(리팩터링)
500,000개의 데이터를 1분만에 indexing 처리, batch 완료되는데 6~7분정도로 개선
![[Pasted image 20240402174454.png]]


bulk api는 무조건 많이 쏜다고 좋은 것은 아니다. 벌크 사이즈를 클러스터 구성이나 데이터 크기 등에 따라서 보통 5~15에서 시작하여 테스트를 진행하면서 맞춰가기
![[Pasted image 20240402174546.png]]

## 부분 데이터 색인
이미 색인된 데이터를 최신화 데이터로 재색인해주는 과정
1. 카프카 토픽 발행(PRODUCT-UPDATED)
![[Pasted image 20240402174810.png]]

2. 발행된 토픽을 이용하여 cunsumer 쪽에서 해당 최신화 데이터로 동기화하고 인덱싱 서버에서 호출,전달
![[Pasted image 20240402174832.png]]

3. 일차적으로 전달받은 데이터는 몽고db에 저장됨 -> 엘라스틱서치 서버가 갑자기 다운되거나 네트워크 이슈 등 장애가 발생할수 있다는 가정 -> 재색인의 실패를 방지하기 위해 일차적으로 저장

![[Pasted image 20240402175045.png]]

4. 스케쥴러로 10초마다 전체색인이 일어나는지 체크, 일어나고 있지 않다면 키 점유 후 몽고 db에서 데이터를 가져와 엘라스틱서치에서 부분 색인, 재색인
![[Pasted image 20240402175058.png]]

+ 몽고db에 저장되는 데이터 구조 (update: 최신화)
![[Pasted image 20240402175319.png]]

부분 색인도 bulk, 분기로 update/delete 확인
![[Pasted image 20240402175341.png]]